{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy\n",
    "import heapq\n",
    "import time\n",
    "import json\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PIXNET_Recommendation:\n",
    "    \n",
    "    def __init__(self,training_data_folder=\"data/training\",test_data_file_path=\"data/testing.json\",target_file_path=\"tmp/recommendation\",k=20):\n",
    "        self.training_data_folder = training_data_folder\n",
    "        self.test_data_file_path = test_data_file_path\n",
    "        self.target_file_path = target_file_path\n",
    "        self.k = k\n",
    "    \n",
    "    def load_data(self):\n",
    "        data_set ={}\n",
    "        training_files = os.listdir(self.training_data_folder)\n",
    "        for filename in training_files:\n",
    "            for line in open(\"%s/%s\"%(self.training_data_folder,filename)):\n",
    "                data_json = json.loads(line.strip())\n",
    "                if data_json['cookie_pta'] not in data_set:\n",
    "                    data_set[data_json['cookie_pta']]={}\n",
    "                data_set[data_json['cookie_pta']][data_json['author_id']] = 1\n",
    "        v = DictVectorizer(sparse=True)\n",
    "        X = v.fit_transform(data_set.values()).T\n",
    "        author = v.get_feature_names()\n",
    "        self.data_set =data_set\n",
    "        self.X = X\n",
    "        self.author = author\n",
    "    \n",
    "    def calculate_item_similarity(self):\n",
    "        X = self.X\n",
    "        author = self.author\n",
    "        distance = sum(X.T.toarray())\n",
    "        similarity_tmp_file = open(\"tmp/similarity_top10\",\"w\")\n",
    "        count = 0\n",
    "        size_per_loop =1000\n",
    "        while count< X.shape[0]:\n",
    "            size_max = min(count+size_per_loop,X.shape[0])-count\n",
    "            similarity = X[count:min(count+size_per_loop,X.shape[0])].dot(X.T).toarray()\n",
    "            for i in xrange(size_max):\n",
    "                similarity[i] = similarity[i]/numpy.sqrt(distance[count+i])\n",
    "            similarity = similarity.T\n",
    "            for i in xrange(X.shape[0]):\n",
    "                similarity[i] = numpy.round(similarity[i]/numpy.sqrt(distance[i]),2)\n",
    "            similarity = similarity.T\n",
    "            for i in xrange(size_max):\n",
    "                rank = []\n",
    "                for j in xrange(X.shape[0]):\n",
    "                    if similarity[i][j] >0.99:\n",
    "                        similarity[i][j] = 0\n",
    "                    rank.append(similarity[i][j])\n",
    "                top_k_similarity = heapq.nlargest(self.k, xrange(len(rank)), rank.__getitem__)\n",
    "                data =[]\n",
    "                for j in xrange(len(top_k_similarity)):\n",
    "                    data.append(\"%s,%.2f\"%(author[top_k_similarity[j]],rank[top_k_similarity[j]]))\n",
    "                similarity_tmp_file.write(\";\".join(data)+\"\\n\")\n",
    "            del similarity\n",
    "            count+=size_per_loop\n",
    "        similarity_tmp_file.close()\n",
    "    \n",
    "    def load_recommend_target(self):\n",
    "        target_file = open(self.test_data_file_path)\n",
    "        questions = {}\n",
    "        for i in target_file:\n",
    "            j =json.loads(i)\n",
    "            questions[j['cookie_pta']] = 1\n",
    "        target_file.close()\n",
    "        self.questions= questions\n",
    "    \n",
    "    def recommend_from_item_similarity(self):\n",
    "        data_set =self.data_set\n",
    "        questions = self.questions\n",
    "        author = self.author\n",
    "        f = open(\"tmp/similarity_top10\")\n",
    "        count =0\n",
    "        author_recommend = {}\n",
    "        for i in f:\n",
    "            r =i.strip().split(\";\")\n",
    "            author_recommend[author[count]] = {}\n",
    "            for j in r:\n",
    "                a = j.split(\",\")\n",
    "                author_recommend[author[count]][a[0]] = float(a[1])\n",
    "            count +=1\n",
    "        f_out = open(self.target_file_path,\"w\")\n",
    "        for i in questions.keys():\n",
    "            log = data_set[i]\n",
    "            recommend_author = {}\n",
    "            for author_id in log.keys():\n",
    "                for r_author in author_recommend[author_id]:\n",
    "                    if r_author in log:\n",
    "                        continue\n",
    "                    if r_author not in recommend_author:\n",
    "                        recommend_author[r_author] = 0\n",
    "                    recommend_author[r_author] += author_recommend[author_id][r_author]\n",
    "            js = {\"cookie_pta\":i,\"author_id\":heapq.nlargest(len(recommend_author)/20,recommend_author,key=recommend_author.__getitem__)}\n",
    "            f_out.write(json.dumps(js)+\"\\n\")\n",
    "        f_out.close()\n",
    "\n",
    "    def main(self):\n",
    "        self.load_data()\n",
    "        self.calculate_item_similarity()\n",
    "        self.load_recommend_target()\n",
    "        self.recommend_from_item_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommendation = PIXNET_Recommendation()\n",
    "recommendation.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
